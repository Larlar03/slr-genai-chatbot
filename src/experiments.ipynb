{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "# Get the parent directory (one level above the current working directory)\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "# Construct the path to the .env file in the parent directory\n",
    "dotenv_path = os.path.join(parent_dir, \".env\")\n",
    "# Load environment variables from the .env file\n",
    "_ = load_dotenv(dotenv_path)\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load document\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(file_path=\"../documents/events.csv\")\n",
    "data = loader.load()\n",
    "len(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split documents (not needed for single csv file as it is already split into lines)\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "# # Chunk size is new linewith separator set\n",
    "#     # chunk_size =\n",
    "#     chunk_overlap  = 2,\n",
    "#     separators=\"\\n\"\n",
    "# )\n",
    "# docs = text_splitter.split_documents(data)\n",
    "# print(len(data))\n",
    "# print(len(docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "dotenv_path = os.path.join(parent_dir, \".env\")\n",
    "_ = load_dotenv(dotenv_path)\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# vector store\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "output_directory = \"../documents/faiss_db\"\n",
    "!rm -rf ./documents/faiss_db  # remove old database files if any\n",
    "\n",
    "vectordb = FAISS.from_documents(\n",
    "data,\n",
    "embeddings,\n",
    ")\n",
    "\n",
    "# save vector store\n",
    "vectordb.save_local(output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vector store\n",
    "events_db = FAISS.load_local(output_directory, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity search\n",
    "query = \"What photography events are happening in August?\"\n",
    "docs = events_db.similarity_search(query, k=5)\n",
    "print(len(docs))\n",
    "for doc in docs:\n",
    "    print(doc.page_content[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximal marginal relevance search - to achieve both relevance (semantic similarity) and diversity to the query\n",
    "docs = events_db.max_marginal_relevance_search(query, k=5, fetch_k=20)\n",
    "for doc in docs:\n",
    "    print(doc.page_content[:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector store-backed retriever\n",
    "retriever = events_db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5})\n",
    "docs = retriever.get_relevant_documents(\"What photography events are happening in August?\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.page_content[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RetrievalQA - question answering with prompt\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.5)\n",
    "retriever = events_db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5})\n",
    "\n",
    "# Build prompt\n",
    "prompt_template = \"\"\"You are a help assistant at www.artrabbit.com. Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "PROMPT = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")\n",
    "\n",
    "question = \"What photography exhibitions are happening in August?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]\n",
    "# result[\"source_documents\"][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags=None metadata=None vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x15f5d3690> search_type='mmr' search_kwargs={'k': 5}\n"
     ]
    }
   ],
   "source": [
    "# RetrievalQA - question answering with refine chain type\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.5)\n",
    "retriever = events_db.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 5})\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type=\"refine\"\n",
    ")\n",
    "\n",
    "question = \"What photography exhibitions are happening in August?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]\n",
    "# result[\"source_documents\"][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversational retrieval chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "retriever = events_db.as_retriever(search_kwargs={\"k\": 5})\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.5)\n",
    "\n",
    "# build prompt\n",
    "prompt_template = \"\"\"You are a help assistant at www.artrabbit.com having a conversation with a person who is looking for something creative adn cultural to do.\n",
    "Use the following pieces of context to provide a concise answer to the question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Chat History: {chat_history}\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "PROMPT = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "# run chain\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "question = \"What photography exhibitions are happening in July?\"\n",
    "result = qa_chain({\"question\": question})\n",
    "result['answer']\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
